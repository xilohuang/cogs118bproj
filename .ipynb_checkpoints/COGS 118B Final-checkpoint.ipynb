{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import joblib\n",
    "from scipy.stats import sem\n",
    "import statistics\n",
    "import random\n",
    "from combat.pycombat import pycombat\n",
    "from openTSNE import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_raw = pd.read_csv('Medicalpremium.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>BloodPressureProblems</th>\n",
       "      <th>AnyTransplants</th>\n",
       "      <th>AnyChronicDiseases</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>KnownAllergies</th>\n",
       "      <th>HistoryOfCancerInFamily</th>\n",
       "      <th>NumberOfMajorSurgeries</th>\n",
       "      <th>PremiumPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>986 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Diabetes  BloodPressureProblems  AnyTransplants  AnyChronicDiseases  \\\n",
       "0     45         0                      0               0                   0   \n",
       "1     60         1                      0               0                   0   \n",
       "2     36         1                      1               0                   0   \n",
       "3     52         1                      1               0                   1   \n",
       "4     38         0                      0               0                   1   \n",
       "..   ...       ...                    ...             ...                 ...   \n",
       "981   18         0                      0               0                   0   \n",
       "982   64         1                      1               0                   0   \n",
       "983   56         0                      1               0                   0   \n",
       "984   47         1                      1               0                   0   \n",
       "985   21         0                      0               0                   0   \n",
       "\n",
       "     Height  Weight  KnownAllergies  HistoryOfCancerInFamily  \\\n",
       "0       155      57               0                        0   \n",
       "1       180      73               0                        0   \n",
       "2       158      59               0                        0   \n",
       "3       183      93               0                        0   \n",
       "4       166      88               0                        0   \n",
       "..      ...     ...             ...                      ...   \n",
       "981     169      67               0                        0   \n",
       "982     153      70               0                        0   \n",
       "983     155      71               0                        0   \n",
       "984     158      73               1                        0   \n",
       "985     158      75               1                        0   \n",
       "\n",
       "     NumberOfMajorSurgeries  PremiumPrice  \n",
       "0                         0         25000  \n",
       "1                         0         29000  \n",
       "2                         1         23000  \n",
       "3                         2         28000  \n",
       "4                         1         23000  \n",
       "..                      ...           ...  \n",
       "981                       0         15000  \n",
       "982                       3         28000  \n",
       "983                       1         29000  \n",
       "984                       1         39000  \n",
       "985                       1         15000  \n",
       "\n",
       "[986 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate X and y\n",
    "def separate_Xy(data):\n",
    "    \n",
    "    X_names = data.columns.values.tolist()\n",
    "    X_names.remove('PremiumPrice')\n",
    "    X = data[X_names]\n",
    "    y = data['PremiumPrice']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code modified based on openTSNE examples\n",
    "original author: @ pavlin-policar\n",
    "\"\"\"\n",
    "def plot(\n",
    "    x,\n",
    "    y,\n",
    "    ax=None,\n",
    "    title=None,\n",
    "    draw_legend=True,\n",
    "    draw_centers=False,\n",
    "    draw_cluster_labels=False,\n",
    "    colors=None,\n",
    "    legend_kwargs=None,\n",
    "    label_order=None,\n",
    "    **kwargs\n",
    "):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = matplotlib.pyplot.subplots(figsize=(8, 8))\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plot_params = {\"alpha\": kwargs.get(\"alpha\", 0.6), \"s\": kwargs.get(\"s\", 1)}\n",
    "\n",
    "    # Create main plot\n",
    "    if label_order is not None:\n",
    "        assert all(np.isin(np.unique(y), label_order))\n",
    "        classes = [l for l in label_order if l in np.unique(y)]\n",
    "    else:\n",
    "        classes = np.unique(y)\n",
    "    if colors is None:\n",
    "        default_colors = matplotlib.rcParams[\"axes.prop_cycle\"]\n",
    "        colors = {k: v[\"color\"] for k, v in zip(classes, default_colors())}\n",
    "\n",
    "    point_colors = list(map(colors.get, y))\n",
    "\n",
    "    ax.scatter(x[:, 0], x[:, 1], c=point_colors, rasterized=True, **plot_params)\n",
    "\n",
    "    # Plot mediods\n",
    "    if draw_centers:\n",
    "        centers = []\n",
    "        for yi in classes:\n",
    "            mask = yi == y\n",
    "            centers.append(np.median(x[mask, :2], axis=0))\n",
    "        centers = np.array(centers)\n",
    "\n",
    "        center_colors = list(map(colors.get, classes))\n",
    "        ax.scatter(\n",
    "            centers[:, 0], centers[:, 1], c=center_colors, s=12, alpha=1, edgecolor=\"k\"\n",
    "        )\n",
    "\n",
    "        # Draw mediod labels\n",
    "        if draw_cluster_labels:\n",
    "            for idx, label in enumerate(classes):\n",
    "                ax.text(\n",
    "                    centers[idx, 0],\n",
    "                    centers[idx, 1] + 2.2,\n",
    "                    label,\n",
    "                    fontsize=kwargs.get(\"fontsize\", 6),\n",
    "                    horizontalalignment=\"center\",\n",
    "                )\n",
    "\n",
    "    # Hide ticks and axis\n",
    "    ax.set_xticks([]), ax.set_yticks([]), ax.axis(\"off\")\n",
    "\n",
    "    if draw_legend:\n",
    "        legend_handles = [\n",
    "            matplotlib.lines.Line2D(\n",
    "                [],\n",
    "                [],\n",
    "                marker=\"s\",\n",
    "                color=\"w\",\n",
    "                markerfacecolor=colors[yi],\n",
    "                ms=10,\n",
    "                alpha=1,\n",
    "                linewidth=0,\n",
    "                label=yi,\n",
    "                markeredgecolor=\"k\",\n",
    "            )\n",
    "            for yi in classes\n",
    "        ]\n",
    "        legend_kwargs_ = dict(loc=\"center left\", bbox_to_anchor=(1, 0.5), frameon=False, )\n",
    "        if legend_kwargs is not None:\n",
    "            legend_kwargs_.update(legend_kwargs)\n",
    "        ax.legend(handles=legend_handles, **legend_kwargs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the distribution of the dataset\n",
    "X, y = separate_Xy(df_raw)\n",
    "ax = plt.subplot()\n",
    "plt.hist(y, color='steelblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate y into 3 groups\n",
    "def separate_y(y):\n",
    "    y_n = copy.deepcopy(y)\n",
    "    for i in range(len(y)):\n",
    "        if y[i] < 20000:\n",
    "            y_n[i] = '< 20000'\n",
    "        elif (y[i] >= 20000) and (y[i] < 32500):\n",
    "            y_n[i] = '20000 to 32500'\n",
    "        else:\n",
    "            y_n[i] = '> 32500'\n",
    "    return y_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1fe4243b65fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     tsne = TSNE(n_components=3, perplexity=i, early_exaggeration_iter=500, early_exaggeration=12, n_iter=1000, \\\n\u001b[0;32m      7\u001b[0m                     initialization='pca', metric='euclidean', n_jobs=-1, neighbors='auto', random_state=42, verbose=False)\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openTSNE\\tsne.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, affinities, initialization)\u001b[0m\n\u001b[0;32m   1225\u001b[0m             \u001b[1;31m# Restore actual affinity probabilities and increase momentum to get\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m             \u001b[1;31m# final, optimized embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m             embedding.optimize(\n\u001b[0m\u001b[0;32m   1228\u001b[0m                 \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m                 \u001b[0mexaggeration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexaggeration\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openTSNE\\tsne.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, n_iter, inplace, propagate_exception, **gradient_descent_params)\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[1;31m# Run gradient descent with the embedding optimizer so gains are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[1;31m# properly updated and kept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m             error, embedding = embedding.optimizer(\n\u001b[0m\u001b[0;32m    672\u001b[0m                 \u001b[0membedding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffinities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptim_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openTSNE\\tsne.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, embedding, P, n_iter, objective_function, learning_rate, momentum, exaggeration, dof, min_gain, max_grad_norm, max_step_norm, theta, n_interpolation_points, min_num_intervals, ints_in_interval, reference_embedding, n_jobs, use_callbacks, callbacks, callbacks_every_iters, verbose)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m             error, gradient = objective_function(\n\u001b[0m\u001b[0;32m   1746\u001b[0m                 \u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m                 \u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openTSNE\\tsne.py\u001b[0m in \u001b[0;36mkl_divergence_bh\u001b[1;34m(embedding, P, dof, bh_params, reference_embedding, should_eval_error, n_jobs, **_)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m     \u001b[1;31m# Compute positive gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m     sum_P, kl_divergence_ = _tsne.estimate_positive_gradient_nn(\n\u001b[0m\u001b[0;32m   1448\u001b[0m         \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score = float('-inf')\n",
    "best_embedding = None\n",
    "best_perplexity = 0\n",
    "y_n = separate_y(y)\n",
    "for i in range(16, 160):\n",
    "    tsne = TSNE(n_components=3, perplexity=i, early_exaggeration_iter=500, early_exaggeration=12, n_iter=1000, \\\n",
    "                    initialization='pca', metric='euclidean', n_jobs=-1, neighbors='auto', random_state=42, verbose=False)\n",
    "    embedding = tsne.fit(X)\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42).fit(embedding)\n",
    "    score = kmeans.score(embedding)\n",
    "    if score > best_score:\n",
    "        best_score = copy.deepcopy(score)\n",
    "        best_embedding = copy.deepcopy(embedding)\n",
    "        best_perplexity = copy.deepcopy(i)\n",
    "plot(best_embedding, y_n, title='perplexity: '+str(best_perplexity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression_X = df_raw.iloc[:,0:10]\n",
    "df_regression_Y = df_raw.iloc[:,10:11]\n",
    "Re_train_X, Re_test_X, Re_train_Y, Re_test_Y = train_test_split(df_regression_X, df_regression_Y, test_size = 0.2, random_state = 200)\n",
    "reg = LinearRegression().fit(Re_train_X, Re_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6495236953211784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(Re_train_X, Re_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6097707687483553"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(Re_test_X, Re_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying random forest regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression_X = df_raw.iloc[:,0:10]\n",
    "df_regression_Y = df_raw.iloc[:,10:11]\n",
    "Re_train_X, Re_test_X, Re_train_Y, Re_test_Y = train_test_split(df_regression_X, df_regression_Y, test_size = 0.2, random_state = 200)\n",
    "regr = RandomForestRegressor(n_jobs = -1)\n",
    "regr.fit(Re_train_X,Re_train_Y)\n",
    "Re_train_predict = regr.predict(Re_train_X)\n",
    "Re_train_predict = np.array(Re_train_predict)\n",
    "Re_train_predict = Re_train_predict.reshape((788,1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705227213570106"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(Re_train_X,Re_train_Y , sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7985678449859266"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(Re_test_X,Re_test_Y,sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regression_X = df_raw.iloc[:,0:10]\n",
    "df_regression_Y = df_raw.iloc[:,10:11]\n",
    "Re_train_X, Re_test_X, Re_train_Y, Re_test_Y = train_test_split(df_regression_X, df_regression_Y, test_size = 0.2, random_state = 200)\n",
    "poly = PolynomialFeatures(degree = 3)\n",
    "poly_x = poly.fit_transform(Re_train_X)\n",
    "poly_test_x = poly.fit_transform(Re_test_X)\n",
    "lin_reg2 = LinearRegression()\n",
    "lin_reg2.fit(poly_x, Re_train_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8245859736519049"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.score(poly_x, Re_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.7718755266124826"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.score(poly_test_x, Re_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%first` not found.\n"
     ]
    }
   ],
   "source": [
    "# first randomly pick 80% of data and divide into >20000 and <=20000 group\n",
    "# then calculate group mean with normalization and train two decision trees\n",
    "# apply the algorithm to the test group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clu_train, Clu_test = train_test_split(df_raw, test_size = 0.2, random_state = 200)\n",
    "Clu_train1 = Clu_train[Clu_train['PremiumPrice'] > 20000]\n",
    "Clu_train2 = Clu_train[Clu_train['PremiumPrice'] <= 20000]\n",
    "Clu_train1_X = Clu_train1.iloc[:,0:10]\n",
    "Clu_train1_Y = Clu_train1.iloc[:,10:11]\n",
    "Clu_train2_X = Clu_train2.iloc[:,0:10]\n",
    "Clu_train2_Y = Clu_train2.iloc[:,10:11]\n",
    "Clu_train1_X_norm = preprocessing.normalize(Clu_train1_X, axis = 0)\n",
    "Clu_train2_X_norm = preprocessing.normalize(Clu_train2_X, axis = 0)\n",
    "regr1 = RandomForestRegressor(n_jobs = -1)\n",
    "regr1.fit(Clu_train1_X_norm, Clu_train1_Y)\n",
    "regr2 = RandomForestRegressor(n_jobs = -1)\n",
    "regr2.fit(Clu_train2_X_norm, Clu_train2_Y)\n",
    "Mean1 = Clu_train1_X_norm.mean(axis = 0)\n",
    "Mean2 = Clu_train2_X_norm.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9713688572586423"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr1.score(Clu_train1_X_norm, Clu_train1_Y , sample_weight=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
